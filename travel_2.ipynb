{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Travel Behavior Analysis Pipeline\n",
    "\n",
    "This notebook implements a pipeline to predict tourist spending categories using SVM and PyTorch Neural Networks.\n",
    "\n",
    "### Key Steps:\n",
    "1. **Data Cleaning**: Handling missing values and specific string formatting issues.\n",
    "2. **Ordinal Encoding**: Preserving the rank order of features like Age and Trip Duration.\n",
    "3. **Model 1**: Support Vector Machine (Scikit-Learn).\n",
    "4. **Model 2**: Deep Neural Network (PyTorch with GPU).\n",
    "5. **Submission**: Generating the final CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully.\n",
      "Train Shape: (12654, 25)\n",
      "Test Shape: (5852, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>travel_companions</th>\n",
       "      <th>num_females</th>\n",
       "      <th>num_males</th>\n",
       "      <th>main_activity</th>\n",
       "      <th>visit_purpose</th>\n",
       "      <th>is_first_visit</th>\n",
       "      <th>mainland_stay_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>food_included</th>\n",
       "      <th>domestic_transport_included</th>\n",
       "      <th>sightseeing_included</th>\n",
       "      <th>guide_included</th>\n",
       "      <th>insurance_included</th>\n",
       "      <th>days_booked_before_trip</th>\n",
       "      <th>arrival_weather</th>\n",
       "      <th>total_trip_days</th>\n",
       "      <th>has_special_requirements</th>\n",
       "      <th>spend_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tour_idftaa27vp</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>45-64</td>\n",
       "      <td>With Spouse and Children</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Beach Tourism</td>\n",
       "      <td>Leisure and Holidays</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cloudy,</td>\n",
       "      <td>30+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tour_iduck75m57</td>\n",
       "      <td>KENYA</td>\n",
       "      <td>45-64</td>\n",
       "      <td>Alone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Conference Tourism</td>\n",
       "      <td>Meetings and Conference</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>15-30</td>\n",
       "      <td>sunny,</td>\n",
       "      <td>30+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tour_id8y3w40h8</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>25-44</td>\n",
       "      <td>With Other Friends/Relatives</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cultural Tourism</td>\n",
       "      <td>Meetings and Conference</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>90+</td>\n",
       "      <td>sunny,</td>\n",
       "      <td>30+</td>\n",
       "      <td>none</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tour_idkoh8mkgr</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>25-44</td>\n",
       "      <td>With Spouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Widlife Tourism</td>\n",
       "      <td>Leisure and Holidays</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>8-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tour_idkmsfa00a</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>25-44</td>\n",
       "      <td>With Spouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Beach Tourism</td>\n",
       "      <td>Leisure and Holidays</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>90+</td>\n",
       "      <td>sunny,</td>\n",
       "      <td>7-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id       country age_group             travel_companions  \\\n",
       "0  tour_idftaa27vp        FRANCE     45-64      With Spouse and Children   \n",
       "1  tour_iduck75m57         KENYA     45-64                         Alone   \n",
       "2  tour_id8y3w40h8  SOUTH AFRICA     25-44  With Other Friends/Relatives   \n",
       "3  tour_idkoh8mkgr         ITALY     25-44                   With Spouse   \n",
       "4  tour_idkmsfa00a         ITALY     25-44                   With Spouse   \n",
       "\n",
       "   num_females  num_males       main_activity            visit_purpose  \\\n",
       "0          1.0        2.0       Beach Tourism     Leisure and Holidays   \n",
       "1          1.0        0.0  Conference Tourism  Meetings and Conference   \n",
       "2          2.0        0.0    Cultural Tourism  Meetings and Conference   \n",
       "3          1.0        1.0     Widlife Tourism     Leisure and Holidays   \n",
       "4          1.0        1.0       Beach Tourism     Leisure and Holidays   \n",
       "\n",
       "  is_first_visit  mainland_stay_nights  ...  food_included  \\\n",
       "0            Yes                     0  ...             No   \n",
       "1            Yes                     6  ...             No   \n",
       "2             No                     4  ...             No   \n",
       "3            Yes                     0  ...            Yes   \n",
       "4            Yes                     0  ...            Yes   \n",
       "\n",
       "  domestic_transport_included sightseeing_included guide_included  \\\n",
       "0                          No                   No             No   \n",
       "1                          No                   No             No   \n",
       "2                          No                   No             No   \n",
       "3                         Yes                  Yes            Yes   \n",
       "4                          No                   No             No   \n",
       "\n",
       "  insurance_included days_booked_before_trip arrival_weather total_trip_days  \\\n",
       "0                 No                     NaN         cloudy,             30+   \n",
       "1                 No                  15-30           sunny,             30+   \n",
       "2                 No                     90+          sunny,             30+   \n",
       "3                 No                    8-14             NaN             NaN   \n",
       "4                 No                     90+          sunny,            7-14   \n",
       "\n",
       "  has_special_requirements spend_category  \n",
       "0                      NaN            1.0  \n",
       "1                      NaN            2.0  \n",
       "2                     none            2.0  \n",
       "3                     none            0.0  \n",
       "4                      NaN            0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets (Assuming files are in the current directory)\n",
    "try:\n",
    "    train_df = pd.read_csv('travel/train.csv')\n",
    "    test_df = pd.read_csv('travel/test.csv')\n",
    "    print(\"Datasets loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv or test.csv not found. Please upload the data.\")\n",
    "\n",
    "# Save trip_ids for submission later\n",
    "test_ids = test_df['trip_id']\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Train Shape: {train_df.shape}\")\n",
    "print(f\"Test Shape: {test_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing & Feature Engineering\n",
    "\n",
    "This is the most critical step. We will define explicit mappings for Ordinal features to ensure the model understands that '45-64' is \"greater\" than '25-44'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal encoding complete. Preparing for OneHot and Scaling...\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- 1. Clean String Columns ---\n",
    "    # Sometimes data has trailing commas or spaces based on the image provided\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].str.strip().str.replace(',', '', regex=False)\n",
    "\n",
    "    # --- 2. Ordinal Encoding Mappings ---\n",
    "    \n",
    "    # Age Group\n",
    "    age_map = {\n",
    "        '<18': 0, '15-24': 1, '25-44': 2, '45-64': 3, '65+': 4\n",
    "    }\n",
    "    # Map unlisted values to a default or mode if necessary, here we stick to knowns\n",
    "    df['age_group'] = df['age_group'].map(age_map).fillna(2) # Fill NaN with mode (approx)\n",
    "\n",
    "    # Total Trip Days\n",
    "    trip_days_map = {\n",
    "        '< 24 hours': 0, '1-3': 1, '4-6': 2, '7-14': 3, \n",
    "        '15-30': 4, '31-60': 5, '61-90': 6, '90+': 7\n",
    "    }\n",
    "    df['total_trip_days'] = df['total_trip_days'].map(trip_days_map).fillna(3)\n",
    "\n",
    "    # Days Booked Before Trip\n",
    "    booking_map = {\n",
    "        '0-7': 0, '8-14': 1, '15-30': 2, '31-60': 3, '61-90': 4, '90+': 5\n",
    "    }\n",
    "    df['days_booked_before_trip'] = df['days_booked_before_trip'].map(booking_map).fillna(2)\n",
    "\n",
    "    # Binary Yes/No Columns\n",
    "    binary_cols = [\n",
    "        'is_first_visit', 'intl_transport_included', 'accomodation_included', \n",
    "        'food_included', 'domestic_transport_included', 'sightseeing_included',\n",
    "        'guide_included', 'insurance_included'\n",
    "    ]\n",
    "    \n",
    "    for col in binary_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map({'Yes': 1, 'No': 0}).fillna(0)\n",
    "\n",
    "    # --- 3. Numerical Feature Selection ---\n",
    "    num_cols = ['num_females', 'num_males', 'mainland_stay_nights', 'island_stay_nights']\n",
    "    \n",
    "    # Fill NaNs in numerical columns\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "    # --- 4. Categorical (One-Hot) ---\n",
    "    # These are nominal, no intrinsic order\n",
    "    nominal_cols = [\n",
    "        'country', 'travel_companions', 'main_activity', 'visit_purpose', \n",
    "        'tour_type', 'info_source', 'arrival_weather', 'has_special_requirements'\n",
    "    ]\n",
    "    \n",
    "    # Return processed parts to be assembled by a pipeline/column transformer\n",
    "    return df, num_cols, nominal_cols\n",
    "\n",
    "# Apply Initial Cleaning / Ordinal Mapping\n",
    "train_df_clean, num_features, nom_features = preprocess_data(train_df)\n",
    "test_df_clean, _, _ = preprocess_data(test_df, is_train=False)\n",
    "\n",
    "# Drop ID column for training\n",
    "X = train_df_clean.drop(columns=['trip_id', 'spend_category'])\n",
    "y = train_df_clean['spend_category']\n",
    "X_test_final = test_df_clean.drop(columns=['trip_id'])\n",
    "\n",
    "print(\"Ordinal encoding complete. Preparing for OneHot and Scaling...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Pipeline\n",
    "We use `ColumnTransformer` to One-Hot encode nominal features and Scale numerical features. Ordinal features are already integers, but we should scale them too so they don't dominate the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Shape: (12654, 25)\n",
      "Shape after dropping missing targets: (12620, 25)\n",
      "Processed Feature Matrix Shape: (12620, 187)\n",
      "Split successful!\n"
     ]
    }
   ],
   "source": [
    "# Identify columns that are already ordinal encoded (integers now)\n",
    "ordinal_cols = ['age_group', 'total_trip_days', 'days_booked_before_trip']\n",
    "binary_cols = ['is_first_visit', 'intl_transport_included', 'accomodation_included', \n",
    "               'food_included', 'domestic_transport_included', 'sightseeing_included',\n",
    "               'guide_included', 'insurance_included']\n",
    "\n",
    "# Preprocessing Pipeline\n",
    "# 1. OneHot for Nominal\n",
    "# 2. Standard Scaler for Numerical + Ordinal\n",
    "# 3. Passthrough for Binary (already 0/1)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features + ordinal_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), nom_features),\n",
    "        ('bin', 'passthrough', binary_cols)\n",
    "    ])\n",
    "\n",
    "# --- REPLACEMENT CODE ---\n",
    "\n",
    "# 1. Filter out rows with missing 'spend_category' in the training set\n",
    "print(f\"Original Train Shape: {train_df_clean.shape}\")\n",
    "train_df_clean = train_df_clean.dropna(subset=['spend_category'])\n",
    "print(f\"Shape after dropping missing targets: {train_df_clean.shape}\")\n",
    "\n",
    "# 2. Ensure target is an integer (standard for PyTorch/Sklearn classification)\n",
    "train_df_clean['spend_category'] = train_df_clean['spend_category'].astype(int)\n",
    "\n",
    "# 3. Define X and y again with the clean data\n",
    "X = train_df_clean.drop(columns=['trip_id', 'spend_category'])\n",
    "y = train_df_clean['spend_category']\n",
    "\n",
    "# 4. Process the features\n",
    "# Note: Re-run your ColumnTransformer (preprocessor) on this new X\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "X_test_processed = preprocessor.transform(X_test_final)\n",
    "\n",
    "print(f\"Processed Feature Matrix Shape: {X_processed.shape}\")\n",
    "\n",
    "# 5. Split Data (Now this will work because y has no NaNs)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_processed, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Split successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 1: Support Vector Machine (SVM)\n",
    "SVM is effective for high-dimensional spaces created by One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "Evaluating SVM...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      1249\n",
      "           1       0.68      0.60      0.64       982\n",
      "           2       0.48      0.69      0.57       293\n",
      "\n",
      "    accuracy                           0.72      2524\n",
      "   macro avg       0.67      0.71      0.68      2524\n",
      "weighted avg       0.74      0.72      0.73      2524\n",
      "\n",
      "SVM Accuracy: 0.7246\n"
     ]
    }
   ],
   "source": [
    "# Initialize SVM\n",
    "# 'rbf' is generally the best default kernel for non-linear relationships\n",
    "# class_weight='balanced' helps if spending categories are unequal\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', class_weight='balanced', random_state=42)\n",
    "\n",
    "print(\"Training SVM...\")\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Evaluating SVM...\")\n",
    "y_pred_svm = svm_model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_val, y_pred_svm):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 2: PyTorch Neural Network\n",
    "Using CUDA for acceleration. We will define a custom Dataset and a flexible MLP architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TravelNet(\n",
      "  (layer1): Linear(in_features=187, out_features=256, bias=True)\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (output): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- Dataset Class ---\n",
    "class TravelDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.long) if y is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        return self.X[idx]\n",
    "\n",
    "# --- Data Loaders ---\n",
    "train_dataset = TravelDataset(X_train, y_train)\n",
    "val_dataset = TravelDataset(X_val, y_val)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Neural Network Architecture ---\n",
    "class TravelNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TravelNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.layer3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.output = nn.Linear(64, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Initialize Model\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 3 # Low, Medium, High\n",
    "\n",
    "model = TravelNet(input_dim, output_dim).to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Loss: 0.5725, Val Acc: 76.66%\n",
      "Epoch [10/50], Loss: 0.5249, Val Acc: 76.31%\n",
      "Epoch [15/50], Loss: 0.4884, Val Acc: 75.55%\n",
      "Epoch [20/50], Loss: 0.4644, Val Acc: 75.55%\n",
      "Epoch [25/50], Loss: 0.4344, Val Acc: 74.21%\n",
      "Epoch [30/50], Loss: 0.4109, Val Acc: 73.77%\n",
      "Epoch [35/50], Loss: 0.3879, Val Acc: 74.25%\n",
      "Epoch [40/50], Loss: 0.3705, Val Acc: 74.17%\n",
      "Epoch [45/50], Loss: 0.3556, Val Acc: 73.61%\n",
      "Epoch [50/50], Loss: 0.3473, Val Acc: 73.42%\n",
      "Training Complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "EPOCHS = 50\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    epoch_acc = 100 * correct / total\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    val_accuracies.append(epoch_acc)\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/len(train_loader):.4f}, Val Acc: {epoch_acc:.2f}%\")\n",
    "\n",
    "print(\"Training Complete.\")\n",
    "\n",
    "# # Plot training progress\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(train_losses, label='Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(val_accuracies, label='Accuracy', color='orange')\n",
    "# plt.title('Validation Accuracy')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Submission File\n",
    "We will use the PyTorch model for final predictions as it usually generalizes better on complex categorical data if tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           trip_id  spend_category\n",
      "0  tour_id8gzpck76               1\n",
      "1  tour_idow1zxkou               0\n",
      "2  tour_idue7esfqz               0\n",
      "3  tour_idnj3mjzpb               0\n",
      "4  tour_ida3us5yk2               0\n",
      "submission.csv created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Prepare Test Loader\n",
    "test_dataset = TravelDataset(X_test_processed)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Create Submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'trip_id': test_ids,\n",
    "    'spend_category': all_preds\n",
    "})\n",
    "\n",
    "# Verify format\n",
    "print(submission.head())\n",
    "\n",
    "# Save\n",
    "submission.to_csv('travel_sub/submission_1.csv', index=False)\n",
    "print(\"submission.csv created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
