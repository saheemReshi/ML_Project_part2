{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tourism Spending Classification\n",
    "## Models: Deep Neural Network (PyTorch/CUDA) & SVM\n",
    "**Goal:** Predict `spend_category` based on trip details.\n",
    "**Hardware:** GPU Acceleration enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOAD DATA ---\n",
    "# Replace 'your_dataset.csv' with your actual file path\n",
    "try:\n",
    "    df = pd.read_csv('travel/train.csv') \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please ensure the data is loaded into the variable 'df'.\")\n",
    "\n",
    "# Initial Cleanup: Drop ID and rows where Target is missing\n",
    "df = df.drop(columns=['trip_id'])\n",
    "df = df.dropna(subset=['spend_category'])\n",
    "\n",
    "# Separate Features and Target\n",
    "X = df.drop('spend_category', axis=1)\n",
    "y = df['spend_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>travel_companions</th>\n",
       "      <th>num_females</th>\n",
       "      <th>num_males</th>\n",
       "      <th>main_activity</th>\n",
       "      <th>visit_purpose</th>\n",
       "      <th>is_first_visit</th>\n",
       "      <th>mainland_stay_nights</th>\n",
       "      <th>island_stay_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>food_included</th>\n",
       "      <th>domestic_transport_included</th>\n",
       "      <th>sightseeing_included</th>\n",
       "      <th>guide_included</th>\n",
       "      <th>insurance_included</th>\n",
       "      <th>days_booked_before_trip</th>\n",
       "      <th>arrival_weather</th>\n",
       "      <th>total_trip_days</th>\n",
       "      <th>has_special_requirements</th>\n",
       "      <th>spend_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FRANCE</td>\n",
       "      <td>45-64</td>\n",
       "      <td>With Spouse and Children</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Beach Tourism</td>\n",
       "      <td>Leisure and Holidays</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cloudy,</td>\n",
       "      <td>30+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KENYA</td>\n",
       "      <td>45-64</td>\n",
       "      <td>Alone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Conference Tourism</td>\n",
       "      <td>Meetings and Conference</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>15-30</td>\n",
       "      <td>sunny,</td>\n",
       "      <td>30+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>25-44</td>\n",
       "      <td>With Other Friends/Relatives</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cultural Tourism</td>\n",
       "      <td>Meetings and Conference</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>90+</td>\n",
       "      <td>sunny,</td>\n",
       "      <td>30+</td>\n",
       "      <td>none</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ITALY</td>\n",
       "      <td>25-44</td>\n",
       "      <td>With Spouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Widlife Tourism</td>\n",
       "      <td>Leisure and Holidays</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>8-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ITALY</td>\n",
       "      <td>25-44</td>\n",
       "      <td>With Spouse</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Beach Tourism</td>\n",
       "      <td>Leisure and Holidays</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>90+</td>\n",
       "      <td>sunny,</td>\n",
       "      <td>7-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        country age_group             travel_companions  num_females  \\\n",
       "0        FRANCE     45-64      With Spouse and Children          1.0   \n",
       "1         KENYA     45-64                         Alone          1.0   \n",
       "2  SOUTH AFRICA     25-44  With Other Friends/Relatives          2.0   \n",
       "3         ITALY     25-44                   With Spouse          1.0   \n",
       "4         ITALY     25-44                   With Spouse          1.0   \n",
       "\n",
       "   num_males       main_activity            visit_purpose is_first_visit  \\\n",
       "0        2.0       Beach Tourism     Leisure and Holidays            Yes   \n",
       "1        0.0  Conference Tourism  Meetings and Conference            Yes   \n",
       "2        0.0    Cultural Tourism  Meetings and Conference             No   \n",
       "3        1.0     Widlife Tourism     Leisure and Holidays            Yes   \n",
       "4        1.0       Beach Tourism     Leisure and Holidays            Yes   \n",
       "\n",
       "   mainland_stay_nights  island_stay_nights  ... food_included  \\\n",
       "0                     0                   7  ...            No   \n",
       "1                     6                   0  ...            No   \n",
       "2                     4                   2  ...            No   \n",
       "3                     0                   7  ...           Yes   \n",
       "4                     0                   7  ...           Yes   \n",
       "\n",
       "  domestic_transport_included sightseeing_included guide_included  \\\n",
       "0                          No                   No             No   \n",
       "1                          No                   No             No   \n",
       "2                          No                   No             No   \n",
       "3                         Yes                  Yes            Yes   \n",
       "4                          No                   No             No   \n",
       "\n",
       "  insurance_included days_booked_before_trip arrival_weather total_trip_days  \\\n",
       "0                 No                     NaN         cloudy,             30+   \n",
       "1                 No                  15-30           sunny,             30+   \n",
       "2                 No                     90+          sunny,             30+   \n",
       "3                 No                    8-14             NaN             NaN   \n",
       "4                 No                     90+          sunny,            7-14   \n",
       "\n",
       "  has_special_requirements spend_category  \n",
       "0                      NaN            1.0  \n",
       "1                      NaN            2.0  \n",
       "2                     none            2.0  \n",
       "3                     none            0.0  \n",
       "4                      NaN            0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Feature Shape: (10096, 195)\n",
      "Target Classes: [0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# --- HEAVY PREPROCESSING ---\n",
    "\n",
    "# 1. Identify Column Types\n",
    "numeric_features = ['num_females', 'num_males', 'mainland_stay_nights', 'island_stay_nights']\n",
    "categorical_features = [\n",
    "    'country', 'age_group', 'travel_companions', 'main_activity', \n",
    "    'visit_purpose', 'is_first_visit', 'tour_type', 'intl_transport_included', \n",
    "    'info_source', 'accomodation_included', 'food_included', \n",
    "    'domestic_transport_included', 'sightseeing_included', 'guide_included', \n",
    "    'insurance_included', 'has_special_requirements'\n",
    "]\n",
    "\n",
    "# 2. Define Transformers\n",
    "# Numeric: Impute missing with median -> Scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical: Impute missing with 'Unknown' -> OneHotEncode\n",
    "# We use 'Unknown' because 'has_special_requirements' has massive missingness likely meaning 'None'\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 3. Combine into Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# 4. Apply Transformations\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# 5. Encode Target (Ensure categories are 0, 1, 2... for PyTorch)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 6. Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Processed Feature Shape: {X_train.shape}\")\n",
    "print(f\"Target Classes: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PYTORCH SETUP (GPU) ---\n",
    "\n",
    "# Convert to Tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeavyNet(\n",
      "  (layer1): Linear(in_features=195, out_features=512, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- MODEL 1: DEEP NEURAL NETWORK ---\n",
    "\n",
    "class HeavyNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(HeavyNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.layer3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.layer4 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.layer3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer4(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(np.unique(y_encoded))\n",
    "\n",
    "model = HeavyNet(input_dim, output_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 0.5648, Acc: 76.27%\n",
      "Epoch [10/100], Loss: 0.5155, Acc: 77.99%\n",
      "Epoch [15/100], Loss: 0.4760, Acc: 80.21%\n",
      "Epoch [20/100], Loss: 0.4336, Acc: 81.18%\n",
      "Epoch [25/100], Loss: 0.4042, Acc: 82.44%\n",
      "Epoch [30/100], Loss: 0.3861, Acc: 83.38%\n",
      "Epoch [35/100], Loss: 0.3579, Acc: 84.80%\n",
      "Epoch [40/100], Loss: 0.3381, Acc: 85.54%\n",
      "Epoch [45/100], Loss: 0.3146, Acc: 86.16%\n",
      "Epoch [50/100], Loss: 0.3044, Acc: 86.69%\n",
      "Epoch [55/100], Loss: 0.2886, Acc: 87.29%\n",
      "Epoch [60/100], Loss: 0.2742, Acc: 88.58%\n",
      "Epoch [65/100], Loss: 0.2550, Acc: 89.07%\n",
      "Epoch [70/100], Loss: 0.2616, Acc: 88.91%\n",
      "Epoch [75/100], Loss: 0.2450, Acc: 89.78%\n",
      "Epoch [80/100], Loss: 0.2425, Acc: 89.88%\n",
      "Epoch [85/100], Loss: 0.2364, Acc: 89.96%\n",
      "Epoch [90/100], Loss: 0.2166, Acc: 90.89%\n",
      "Epoch [95/100], Loss: 0.2244, Acc: 90.58%\n",
      "Epoch [100/100], Loss: 0.2159, Acc: 91.18%\n"
     ]
    }
   ],
   "source": [
    "# --- TRAINING LOOP (PYTORCH) ---\n",
    "EPOCHS = 100\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_acc = 100 * correct / total\n",
    "    loss_history.append(running_loss/len(train_loader))\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/len(train_loader):.4f}, Acc: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Neural Network Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.84      0.81      1174\n",
      "         1.0       0.69      0.64      0.67      1076\n",
      "         2.0       0.47      0.43      0.45       274\n",
      "\n",
      "    accuracy                           0.71      2524\n",
      "   macro avg       0.65      0.64      0.64      2524\n",
      "weighted avg       0.71      0.71      0.71      2524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- EVALUATION (PYTORCH) ---\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"--- Neural Network Results ---\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[str(c) for c in label_encoder.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM... (This might take a moment)\n",
      "--- SVM Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.86      0.82      1174\n",
      "         1.0       0.71      0.74      0.72      1076\n",
      "         2.0       0.78      0.31      0.45       274\n",
      "\n",
      "    accuracy                           0.75      2524\n",
      "   macro avg       0.76      0.64      0.66      2524\n",
      "weighted avg       0.75      0.75      0.74      2524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- MODEL 2: SVM (Support Vector Machine) ---\n",
    "# Note: Sklearn SVM does not run on GPU natively, but we use the preprocessed data.\n",
    "# We use RBF kernel which handles non-linearity well.\n",
    "\n",
    "print(\"Training SVM... (This might take a moment)\")\n",
    "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "svm_preds = svm_model.predict(X_test)\n",
    "\n",
    "print(\"--- SVM Results ---\")\n",
    "print(classification_report(y_test, svm_preds, target_names=[str(c) for c in label_encoder.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 'submission_nn.csv' and 'submission_svm.csv' generated.\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Test Data\n",
    "# Ensure this file exists and has the same columns as training data (minus the target)\n",
    "test_df = pd.read_csv('travel/test.csv') \n",
    "\n",
    "# 2. Isolate IDs for the final file\n",
    "submission_ids = test_df['trip_id']\n",
    "\n",
    "# 3. Preprocess Test Data\n",
    "# MUST use .transform() to use the exact same scaling/encoding as the training set\n",
    "X_test_raw = test_df.drop('trip_id', axis=1)\n",
    "X_test_processed = preprocessor.transform(X_test_raw)\n",
    "\n",
    "# --- NEURAL NETWORK PREDICTION ---\n",
    "model.eval()\n",
    "X_tensor_sub = torch.tensor(X_test_processed, dtype=torch.float32).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tensor_sub)\n",
    "    _, predicted_indices = torch.max(outputs, 1)\n",
    "    # Move to CPU and convert to numpy\n",
    "    nn_preds_indices = predicted_indices.cpu().numpy()\n",
    "\n",
    "# Convert numeric predictions back to original labels (e.g., 'High', 'Low', etc.)\n",
    "nn_final_preds = label_encoder.inverse_transform(nn_preds_indices)\n",
    "\n",
    "# --- SVM PREDICTION ---\n",
    "svm_preds_indices = svm_model.predict(X_test_processed)\n",
    "svm_final_preds = label_encoder.inverse_transform(svm_preds_indices)\n",
    "\n",
    "# --- SAVE OUTPUTS ---\n",
    "# Save Neural Network Submission\n",
    "pd.DataFrame({\n",
    "    'trip_id': submission_ids,\n",
    "    'spend_category': nn_final_preds\n",
    "}).to_csv('travel_sub/submission_nn.csv', index=False)\n",
    "\n",
    "# Save SVM Submission\n",
    "pd.DataFrame({\n",
    "    'trip_id': submission_ids,\n",
    "    'spend_category': svm_final_preds\n",
    "}).to_csv('travel_sub/submission_svm.csv', index=False)\n",
    "\n",
    "print(\"Success: 'submission_nn.csv' and 'submission_svm.csv' generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
